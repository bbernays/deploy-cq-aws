AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: 'Cloudformation for provisioning service required to schedule and execute RDS jobs using AWS CodeBuild'

Parameters:
  CQVersion:
    Description: Tagged version of the CloudQuery Image
    Type: String
    Default: latest
  InvocationRate:
    Description: How often you want the fetch to occur
    Type: String
    Default: rate(60 minutes)
  EnvironmentName:
    Description: An environment name that is prefixed to resource names
    Type: String
    Default: dev
  VpcCIDR:
    Description: Please enter the IP range (CIDR notation) for this VPC
    Type: String
    Default: 10.192.0.0/16

  PublicSubnet1CIDR:
    Description: Please enter the IP range (CIDR notation) for the public subnet in the first Availability Zone
    Type: String
    Default: 10.192.10.0/24

  PublicSubnet2CIDR:
    Description: Please enter the IP range (CIDR notation) for the public subnet in the second Availability Zone
    Type: String
    Default: 10.192.11.0/24

  PrivateSubnet1CIDR:
    Description: Please enter the IP range (CIDR notation) for the private subnet in the first Availability Zone
    Type: String
    Default: 10.192.20.0/24

  PrivateSubnet2CIDR:
    Description: Please enter the IP range (CIDR notation) for the private subnet in the second Availability Zone
    Type: String
    Default: 10.192.21.0/24

  VpcId:
    Description: Please enter the Id of the VPC in which you want to deploy CloudQuery
    Type: String
    Default: ""
  
  PrivateSubnetIds:
    Description: Please enter a comma separated list of Subnet Ids where you want to run CloudQuery and the Database.
    Type: String
    Default: ""
  
  DbUrl:
    Description: Hostname for database
    Type: String
    Default: ""

  SecretArn:
    Description: Please enter a comma separated list of Subnet Ids where you want to run CloudQuery and the Database.
    Type: String
    Default: ""

  
Conditions:
  DeployVPC: !Equals [!Ref VpcId, ""]
  DeployDB: !Equals [!Ref DbUrl, ""]
Resources:
  ####### VPC + Networking Resources #####
  VPC:
    Condition: DeployVPC
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCIDR
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: !Ref EnvironmentName

  InternetGateway:
    Condition: DeployVPC
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Ref EnvironmentName

  InternetGatewayAttachment:
    Condition: DeployVPC
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref VPC

  PublicSubnet1:
    Condition: DeployVPC
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 0, !GetAZs '' ]
      CidrBlock: !Ref PublicSubnet1CIDR
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Public Subnet (AZ1)

  PublicSubnet2:
    Condition: DeployVPC
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 1, !GetAZs  '' ]
      CidrBlock: !Ref PublicSubnet2CIDR
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Public Subnet (AZ2)

  PrivateSubnet1: 
    Condition: DeployVPC
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 0, !GetAZs  '' ]
      CidrBlock: !Ref PrivateSubnet1CIDR
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Private Subnet (AZ1)

  PrivateSubnet2:
    Condition: DeployVPC
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 1, !GetAZs  '' ]
      CidrBlock: !Ref PrivateSubnet2CIDR
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Private Subnet (AZ2)

  NatGateway1EIP:
    Condition: DeployVPC
    Type: AWS::EC2::EIP
    DependsOn: InternetGatewayAttachment
    Properties:
      Domain: vpc

  NatGateway2EIP:
    Condition: DeployVPC
    Type: AWS::EC2::EIP
    DependsOn: InternetGatewayAttachment
    Properties:
      Domain: vpc

  NatGateway1:
    Condition: DeployVPC
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGateway1EIP.AllocationId
      SubnetId: !Ref PublicSubnet1

  NatGateway2:
    Condition: DeployVPC
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGateway2EIP.AllocationId
      SubnetId: !Ref PublicSubnet2

  PublicRouteTable:
    Condition: DeployVPC
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Public Routes

  DefaultPublicRoute:
    Condition: DeployVPC
    Type: AWS::EC2::Route
    DependsOn: InternetGatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnet1RouteTableAssociation:
    Condition: DeployVPC
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet1

  PublicSubnet2RouteTableAssociation:
    Condition: DeployVPC
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet2


  PrivateRouteTable1:
    Condition: DeployVPC
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Private Routes (AZ1)

  DefaultPrivateRoute1:
    Condition: DeployVPC
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway1

  PrivateSubnet1RouteTableAssociation:
    Condition: DeployVPC
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      SubnetId: !Ref PrivateSubnet1

  PrivateRouteTable2:
    Condition: DeployVPC
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} Private Routes (AZ2)

  DefaultPrivateRoute2:
    Condition: DeployVPC
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable2
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway2

  PrivateSubnet2RouteTableAssociation:
    Condition: DeployVPC
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable2
      SubnetId: !Ref PrivateSubnet2

  ECSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${AWS::StackName}-ECS
      GroupDescription: "Allow HTTP/HTTPS inbound and outbound traffic"
      VpcId: !If [DeployVPC, !Ref VPC, !Ref VpcId]
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
  PgServerlessSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${AWS::StackName}-Pg-Serverless-Access
      GroupDescription: Allow postgres inbound traffic
      VpcId: !If [DeployVPC, !Ref VPC, !Ref VpcId]
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          SourceSecurityGroupId: !GetAtt   ECSSecurityGroup.GroupId

####### DB Resources #####
  DBSubnetGroup:
    Condition: DeployDB
    Type: 'AWS::RDS::DBSubnetGroup'
    Properties:
      DBSubnetGroupDescription: !Ref 'AWS::StackName'
      SubnetIds: !Split [ ",",!If [DeployVPC,!Join [ ",", [ !Ref PrivateSubnet1, !Ref PrivateSubnet2 ]], !Ref PrivateSubnetIds] ]
  Cluster:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Condition: DeployDB
    Type: AWS::RDS::DBCluster
    Properties:
      ScalingConfiguration:
        AutoPause: false
        MinCapacity: 2
        MaxCapacity: 8
      Engine: aurora-postgresql
      EngineMode: serverless
      EngineVersion: "11.13"
      DatabaseName: !Sub cloudquery${EnvironmentName}
      MasterUsername: !Sub "{{resolve:secretsmanager:${RdsClusterSecret}::username}}"
      MasterUserPassword: !Sub "{{resolve:secretsmanager:${RdsClusterSecret}::password}}"
      DBClusterIdentifier: !Ref AWS::StackName
      DBSubnetGroupName: !Ref DBSubnetGroup
      BackupRetentionPeriod: 35
      VpcSecurityGroupIds: !Split [ ",",!Join [ ",", [ !Ref ECSSecurityGroup, !Ref PgServerlessSecurityGroup]] ]
  
  RdsClusterSecret:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain    
    Condition: DeployDB
    Type: AWS::SecretsManager::Secret
    Properties:
      Description: This is my rds instance secret
      GenerateSecretString:
        SecretStringTemplate: '{"username": "cloudquery"}'
        GenerateStringKey: password
        PasswordLength: 16
        ExcludePunctuation: true

  #### ECS Cluster:
  ECSCluster:
    Type: 'AWS::ECS::Cluster'
  ScheduledWorkerTask:
    Type: 'AWS::ECS::TaskDefinition'
    Properties:
      RequiresCompatibilities:
        - FARGATE
      NetworkMode: awsvpc
      Cpu: 1024
      Memory: 2GB
      ExecutionRoleArn: !GetAtt ExecutionRole.Arn
      TaskRoleArn: !GetAtt ExecutionRole.Arn
      ContainerDefinitions:
        - Essential: 'true'
          Image: !Sub ghcr.io/cloudquery/cloudquery:${CQVersion}
          Name: ScheduledWorker
          Environment:
            - 
              Name: CQ_VAR_DB_URL
              Value: !If [DeployDB, !GetAtt Cluster.Endpoint.Address, !Ref DbUrl]
            - Name: CQ_VAR_DB_NAME
              Value: !Sub cloudquery${EnvironmentName}
          Secrets:
            - Name: CQ_VAR_DB_PASSWORD
              ValueFrom: !If [DeployDB, !Sub '${RdsClusterSecret}:password::', !Sub '${SecretArn}:password::']
            - Name: CQ_VAR_DB_USER
              ValueFrom: !If [DeployDB, !Sub '${RdsClusterSecret}:username::', !Sub '${SecretArn}:username::']
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: !Ref LogGroup
              awslogs-region: !Ref AWS::Region
              awslogs-stream-prefix: !Ref AWS::StackName
  LogGroup:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain  
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 14
  
  ####### S3 Bucket + Resources for storing config files#####
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  S3BucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      Bucket:
        Ref: S3Bucket
      PolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              AWS: !GetAtt ExecutionRole.Arn
            Action:
              - 's3:getObject'
            Resource: 
              - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}/*
          - Action:
              - 's3:*'
            Effect: Deny
            Resource: 
              - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}/*
              - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}
            Principal: '*'
            Condition:
              Bool:
                  'aws:SecureTransport': 'false'
  S3CustomResource:
    Type: Custom::S3CustomResource
    Properties:
      ServiceToken: !GetAtt AWSLambdaFunction.Arn
      S3_bucket: !Ref S3Bucket
  AWSLambdaFunction:
     Type: "AWS::Lambda::Function"
     Properties:
       Description: "Work with S3 Buckets!"
       FunctionName: !Sub '${AWS::StackName}-${AWS::Region}-lambda'
       Handler: index.handler
       Role: !GetAtt AWSLambdaExecutionRole.Arn
       Timeout: 360
       Runtime: python3.9
       Code:
         ZipFile: |
          import boto3
          import cfnresponse
          def handler(event, context):
              the_event = event['RequestType']
              response_data = {}
              s_3 = boto3.client('s3')
              # Retrieve parameters
              the_bucket = event['ResourceProperties']['S3_bucket']
              try:
                  if the_event == 'Delete':
                      print("Deleting S3 content...")
                      b_operator = boto3.resource('s3')
                      b_operator.Bucket(str(the_bucket)).objects.all().delete()
                  print("Operation successful!")
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
              except Exception as e:
                  print("Operation failed...")
                  print(str(e))
                  response_data['Data'] = str(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, response_data)
  AWSLambdaExecutionRole:
     Type: AWS::IAM::Role
     Properties:
       AssumeRolePolicyDocument:
         Statement:
         - Action:
           - sts:AssumeRole
           Effect: Allow
           Principal:
             Service:
             - lambda.amazonaws.com
         Version: '2012-10-17'
       Path: "/"
       Policies:
       - PolicyDocument:
           Statement:
           - Action:
             - logs:CreateLogGroup
             - logs:CreateLogStream
             - logs:PutLogEvents
             Effect: Allow
             Resource: !Sub arn:${AWS::Partition}:logs:*:*:*
           Version: '2012-10-17'
         PolicyName: !Sub ${AWS::StackName}-${AWS::Region}-AWSLambda-CW
       - PolicyDocument:
           Statement:
           - Action:
             - s3:PutObject
             - s3:DeleteObject
             - s3:List*
             Effect: Allow
             Resource:
             - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}/*
             - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}
           Version: '2012-10-17'
         PolicyName: !Sub ${AWS::StackName}-${AWS::Region}-AWSLambda-S3
       RoleName: !Sub ${AWS::StackName}-${AWS::Region}
  
  ####### IAM role for Fargate execution#####
  ExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: ecs-tasks.amazonaws.com
            Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: DenyData
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Deny
                NotResource: 
                  - !Sub arn:${AWS::Partition}:s3:::${S3Bucket}/*
                Action:
                  - s3:GetObject
              -
                Effect: Deny
                Resource: '*'
                Action:
                  - cloudformation:GetTemplate
                  - dynamodb:GetItem
                  - dynamodb:BatchGetItem
                  - dynamodb:Query
                  - dynamodb:Scan
                  - ec2:GetConsoleOutput
                  - ec2:GetConsoleScreenshot
                  - ecr:BatchGetImage
                  - ecr:GetAuthorizationToken
                  - ecr:GetDownloadUrlForLayer
                  - kinesis:Get*
                  - lambda:GetFunction
                  - logs:GetLogEvents
                  - sdb:Select*
                  - sqs:ReceiveMessage
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy'
        - 'arn:aws:iam::aws:policy/ReadOnlyAccess'
        - 'arn:aws:iam::aws:policy/SecretsManagerReadWrite'
  
  ####### Distributed Locking Mechanism#####
  ApplicationRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - 
            Effect: "Allow"
            Principal: 
              Service: 
                - "states.amazonaws.com"
                - "lambda.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Policies:
        - PolicyName: AppPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                - events:PutTargets
                - events:PutRule
                - events:DescribeRule
                - states:StartExecution
                - xray:PutTraceSegments
                - xray:PutTelemetryRecords
                - xray:GetSamplingRules
                - xray:GetSamplingTargets
                - logs:CreateLogDelivery
                - logs:GetLogDelivery
                - logs:UpdateLogDelivery
                - logs:DeleteLogDelivery
                - logs:ListLogDeliveries
                - logs:PutResourcePolicy
                - logs:DescribeResourcePolicies
                - logs:DescribeLogGroups
                - cloudwatch:PutMetricData
                Resource: '*'
              -
                Effect: Allow
                Action:
                - dynamodb:*
                Resource: !GetAtt TableSemaphore.Arn
              - Action:
                  - 'iam:PassRole'
                Effect: Allow
                Resource:
                  - !GetAtt ExecutionRole.Arn
              - 
                Action:
                  - 'ecs:RunTask'
                Effect: Allow
                Resource: '*'
                Condition:
                  ArnEquals:
                    'ecs:cluster': !GetAtt ECSCluster.Arn

  LogGroupStateMachines:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain  
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/states/${AWS::StackName}-StateMachineLogs
  FetchOrchestratorCleanup:
    Type: AWS::Serverless::StateMachine
    Properties:
      Definition:
        Comment: A state machine that will react to completion events and clean up orphaned locks
        StartAt: Transform Input
        States:
          Transform Input:
            Comment: >-
              Transform and mutate input from CloudWatch Events
            Type: Pass
            Next: Get Current Lock Item
            Parameters:
              detail:
                'Input.$': 'States.StringToJson($.detail.input)'
                'executionArn.$': '$.detail.executionArn'
          Get Current Lock Item:
            Comment: >-
              Get info from DDB for the lock item to look and see if this specific owner
              is still holding a lock
            Type: Task
            Resource: arn:aws:states:::dynamodb:getItem
            Parameters:
              TableName: ${TableSemaphore}
              ExpressionAttributeNames:
                '#lockownerid.$': $.detail.executionArn
              Key:
                LockName:
                  'S.$': '$.detail.Input.ConfigLocation'
              ProjectionExpression: '#lockownerid'
            Retry:
              - ErrorEquals:
                  - States.ALL
                IntervalSeconds: 5
                MaxAttempts: 20
                BackoffRate: 1.4
            ResultSelector:
              Item.$: $.Item
              ItemString.$: States.JsonToString($.Item)
            ResultPath: $.lockinfo.currentlockitem
            Next: Check If Lock Is Held
          Check If Lock Is Held:
            Comment: >-
              This state checks to see if the execution in question holds a lock. It can
              tell that by looking for Z, which will be indicative of the timestamp
              value. That will only be there in the stringified version of the data
              returned from DDB if this execution holds a lock
            Type: Choice
            Choices:
              - And:
                  - Variable: $.lockinfo.currentlockitem.ItemString
                    IsPresent: true
                  - Variable: $.lockinfo.currentlockitem.ItemString
                    StringMatches: '*Z*'
                Next: Clean Up Lock
            Default: Success State
          Clean Up Lock:
            Comment: If this lockownerid is still there, then clean it up and release the lock
            Type: Task
            Resource: arn:aws:states:::dynamodb:updateItem
            Parameters:
              TableName: ${TableSemaphore}
              Key:
                LockName:
                  'S.$': '$.detail.Input.ConfigLocation'
              ExpressionAttributeNames:
                '#currentlockcount': currentlockcount
                '#lockownerid.$': $.detail.executionArn
              ExpressionAttributeValues:
                ':decrease':
                  'N': '1'
              UpdateExpression: >-
                SET #currentlockcount = #currentlockcount - :decrease REMOVE
                #lockownerid
              ConditionExpression: attribute_exists(#lockownerid)
              ReturnValues: UPDATED_NEW
            Retry:
              - ErrorEquals:
                  - DynamoDB.ConditionalCheckFailedException
                MaxAttempts: 0
              - ErrorEquals:
                  - States.ALL
                IntervalSeconds: 5
                MaxAttempts: 20
                BackoffRate: 1.4
            Catch:
              - ErrorEquals:
                  - DynamoDB.ConditionalCheckFailedException
                Next: Success State
            Next: Success State
          Success State:
            Type: Succeed

      DefinitionSubstitutions:
        TableSemaphore: !Sub ${AWS::StackName}-locktable
      Tracing:
        Enabled: true
      Role: !GetAtt ApplicationRole.Arn
      Logging:
        Destinations:
          - CloudWatchLogsLogGroup:
              LogGroupArn: !GetAtt  LogGroupStateMachines.Arn
        IncludeExecutionData: TRUE
        Level: "ALL"
      Type: "STANDARD"
      Name: !Sub ${AWS::StackName}-CleanFromIncomplete
      Events:
        RunForIncomplete:
          Type: EventBridgeRule
          Properties:
            Pattern:
              source:
                - "aws.states"
              detail:
                stateMachineArn: 
                  - !Ref FetchOrchestrator
                status:
                  - FAILED
                  - TIMED_OUT
                  - ABORTED
  FetchOrchestrator:
    Type: AWS::Serverless::StateMachine
    Properties:
      Events:
        CWSchedule:
          Type: Schedule
          Properties:
            Schedule: !Ref InvocationRate
            Description: test schedule
            Enabled: true
            Input: !Sub '{"ConfigLocation":"s3://${S3Bucket}/cloudquery.yml"}'
      Definition:
        Comment: A state machine to demonstrate using DynamoDB to implement a semaphore
        StartAt: Get Lock
        States:
          Get Lock:
            Comment: >-
              This parallel state contains the logic to acquire a lock and to handle the
              cases where a lock cannot be Acquired. Containing this in a parallel
              allows for visual separation when viewing the state machine and makes it
              easier to reuse this same logic elsewhere if desired. Because this state
              sets ResultPath: null, it will not manipulate the execution input that is
              passed on to the subsequent part of your statemachine that is responsible
              for doing the work.
            Type: Parallel
            Branches:
              - StartAt: Acquire Lock
                States:
                  Acquire Lock:
                    Comment: >-
                      acquire a lock using a conditional update to DynamoDB. This update
                      will do two things: 1) increment a counter for the number of held
                      locks and 2) add an attribute to the DynamoDB Item with a unique
                      key for this execution and with a value of the time when the lock
                      was Acquired. The Update includes a conditional expression that
                      will fail under two circumstances: 1) if the maximum number of
                      locks have already been distributed or 2) if the current execution
                      already owns a lock. The latter check is important to ensure the
                      same execution doesn't increase the counter more than once. If
                      either of these conditions are not met, then the task will fail
                      with a DynamoDB.ConditionalCheckFailedException error, retry a few
                      times, then if it is still not successful, it will move off to
                      another branch of the workflow. If this is the first time that a
                      given lockname has been used, there will not be a row in DynamoDB,
                      so the update will fail with DynamoDB.AmazonDynamoDBException. In
                      that case, this state sends the workflow to state that will create
                      that row to initialize.
                    Type: Task
                    Resource: arn:aws:states:::dynamodb:updateItem
                    Parameters:
                      TableName: ${TableSemaphore}
                      Key:
                        LockName:
                          'S.$': '$$.Execution.Input.ConfigLocation'
                      ExpressionAttributeNames:
                        '#currentlockcount': currentlockcount
                        '#lockownerid.$': $$.Execution.Id
                      ExpressionAttributeValues:
                        ':increase':
                          'N': '1'
                        ':limit':
                          'N': ${ConcurrentAccessLimit}
                        ':lockacquiredtime':
                          S.$: $$.State.EnteredTime
                      UpdateExpression: >-
                        SET #currentlockcount = #currentlockcount + :increase,
                        #lockownerid = :lockacquiredtime
                      ConditionExpression: >-
                        currentlockcount <> :limit and
                        attribute_not_exists(#lockownerid)
                      ReturnValues: UPDATED_NEW
                    Retry:
                      - ErrorEquals:
                          - DynamoDB.AmazonDynamoDBException
                        MaxAttempts: 0
                      - ErrorEquals:
                          - States.ALL
                        MaxAttempts: 6
                        BackoffRate: 2
                    Catch:
                      - ErrorEquals:
                          - DynamoDB.AmazonDynamoDBException
                        Next: Initialize Lock Item
                        ResultPath: $.lockinfo.acquisitionerror
                      - ErrorEquals:
                          - DynamoDB.ConditionalCheckFailedException
                        Next: Get Current Lock Record
                        ResultPath: $.lockinfo.acquisitionerror
                    End: true
                  Initialize Lock Item:
                    Comment: >-
                      This state handles the case where an item hasn't been created for
                      this lock yet. In that case, it will insert an initial item that
                      includes the lock name as the key and currentlockcount of 0. The
                      Put to DynamoDB includes a conditional expression to fail if the
                      an item with that key already exists, which avoids a race
                      condition if multiple executions start at the same time. There are
                      other reasons that the previous state could fail and end up here,
                      so this is safe in those cases too.
                    Type: Task
                    Resource: arn:aws:states:::dynamodb:putItem
                    Parameters:
                      TableName: ${TableSemaphore}
                      Item:
                        LockName:
                          'S.$': '$$.Execution.Input.ConfigLocation'
                        currentlockcount:
                          'N': '0'
                      ConditionExpression: LockName <> :lockname
                      ExpressionAttributeValues:
                        ':lockname':
                          "S.$": "$$.Execution.Input.ConfigLocation"
                    Catch:
                      - ErrorEquals:
                          - States.ALL
                        Next: Acquire Lock
                        # ResultPath: null
                    Next: Acquire Lock
                    # ResultPath: null
                  Get Current Lock Record:
                    Comment: >-
                      This state is called when the execution is unable to acquire a
                      lock because there limit has either been exceeded or because this
                      execution already holds a lock. I that case, this task loads info
                      from DDB for the current lock item so that the right decision can
                      be made in subsequent states.
                    Type: Task
                    Resource: arn:aws:states:::dynamodb:getItem
                    Parameters:
                      TableName: ${TableSemaphore}
                      ExpressionAttributeNames:
                        '#lockownerid.$': $$.Execution.Id
                      Key:
                        LockName:
                          'S.$': '$$.Execution.Input.ConfigLocation'
                      ProjectionExpression: '#lockownerid'
                    ResultSelector:
                      Item.$: $.Item
                      ItemString.$: States.JsonToString($.Item)
                    ResultPath: $.lockinfo.currentlockitem
                    Next: Check If Lock Already Acquired
                  Check If Lock Already Acquired:
                    Comment: >-
                      This state checks to see if the current execution already holds a
                      lock. It can tell that by looking for Z, which will be indicative
                      of the timestamp value. That will only be there in the stringified
                      version of the data returned from DDB if this execution holds a
                      lock.
                    Type: Choice
                    Choices:
                      - And:
                          - Variable: $.lockinfo.currentlockitem.ItemString
                            IsPresent: true
                          - Variable: $.lockinfo.currentlockitem.ItemString
                            StringMatches: '*Z*'
                        Next: Continue Because Lock Was Already Acquired
                    Default: Wait to Get Lock
                  Continue Because Lock Was Already Acquired:
                    Comment: >-
                      In this state, we have confirmed that lock is already held, so we
                      pass the original execution input into the the function that does
                      the work.
                    Type: Pass
                    End: true
                  Wait to Get Lock:
                    Comment: >-
                      If the lock indeed not been successfully Acquired, then wait for a
                      bit before trying again.
                    Type: Wait
                    Seconds: 3
                    Next: Acquire Lock
            # ResultPath: null
            Next: Do Work
          Do Work:
            Comment: >-
              This is a placeholder for the actual logic of your workflow. By wrapping
              this in a parallel state, you should be able to paste in any statemachine
              defined elsewhere. In this case, to illustrate the behavior, this one will
              run through some pass states and then call a Lambda function that will
              sleep for a period before it returns.
            Type: Parallel
            Branches:
              - StartAt: RunTask
                States:
                  RunTask:
                    Type: Task
                    Resource: arn:aws:states:::ecs:runTask.sync
                    Parameters:
                      Overrides:
                        ContainerOverrides:
                          - Name: ScheduledWorker
                            Command.$: "States.Array('fetch',States.Format('--config={}', $$.Execution.Input.ConfigLocation), '--enable-console-log', '--encode-json')"
                      LaunchType: FARGATE
                      Cluster: ${Cluster}
                      TaskDefinition: ${TaskDefinition}
                      NetworkConfiguration:
                        AwsvpcConfiguration:
                          Subnets:
                            - ${SubnetA}
                            - ${SubnetB}
                          AssignPublicIp: ENABLED
                          SecurityGroups: 
                            - ${SecurityGroupA}
                            - ${SecurityGroupB}
                    Retry:
                      - ErrorEquals:
                          - States.TaskFailed
                        IntervalSeconds: 10
                        MaxAttempts: 3
                        BackoffRate: 2
                    End: true
            Next: Release Lock
          Release Lock:
            Type: Task
            Resource: arn:aws:states:::dynamodb:updateItem
            Parameters:
              TableName: ${TableSemaphore}
              Key:
                LockName:
                  'S.$': '$$.Execution.Input.ConfigLocation'
              ExpressionAttributeNames:
                '#currentlockcount': currentlockcount
                '#lockownerid.$': $$.Execution.Id
              ExpressionAttributeValues:
                ':decrease':
                  'N': '1'
              UpdateExpression: >-
                SET #currentlockcount = #currentlockcount - :decrease REMOVE
                #lockownerid
              ConditionExpression: attribute_exists(#lockownerid)
              ReturnValues: UPDATED_NEW
            Retry:
              - ErrorEquals:
                  - DynamoDB.ConditionalCheckFailedException
                MaxAttempts: 0
              - ErrorEquals:
                  - States.ALL
                MaxAttempts: 5
                BackoffRate: 1.5
            Catch:
              - ErrorEquals:
                  - DynamoDB.ConditionalCheckFailedException
                Next: Success State
                # ResultPath: null
            # ResultPath: null
            Next: Success State
          Success State:
            Type: Succeed

      DefinitionSubstitutions:
        TableSemaphore: !Sub ${AWS::StackName}-locktable
        ConcurrentAccessLimit: 1
        Cluster: !GetAtt ECSCluster.Arn
        SubnetA: !If [DeployVPC,!Ref PrivateSubnet1, " UPDATED-VALUE"]
        SubnetB: !If [DeployVPC,!Ref PrivateSubnet2, " UPDATED-VALUE"]
        SecurityGroupA: !Ref ECSSecurityGroup
        SecurityGroupB: !Ref PgServerlessSecurityGroup
        TaskDefinition: !Ref ScheduledWorkerTask
        S3Bucket: !Ref S3Bucket
      Tracing:
        Enabled: true
      Role: !GetAtt ApplicationRole.Arn
      Logging:
        Destinations:
          - CloudWatchLogsLogGroup:
              LogGroupArn: !GetAtt  LogGroupStateMachines.Arn
        IncludeExecutionData: TRUE
        Level: "ALL"
      Type: "STANDARD"
      Name: !Sub ${AWS::StackName}-ConcurrencyControlledStateMachine
  # Dynamo DB Tables
  TableSemaphore:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain  
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - 
          AttributeName: "LockName"
          AttributeType: "S"
      BillingMode: PAY_PER_REQUEST
      KeySchema: 
        - 
          AttributeName: "LockName"
          KeyType: "HASH"
      TableName: !Sub ${AWS::StackName}-locktable
  RunTaskRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: Allow
            Principal:
              Service:
                - events.amazonaws.com
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Action:
                  - 'ecs:RunTask'
                Condition:
                  ArnEquals:
                    'ecs:cluster': !GetAtt ECSCluster.Arn
                Effect: Allow
                Resource:
                  - '*'
              - Action:
                  - 'iam:PassRole'
                Effect: Allow
                Resource:
                  - !GetAtt ExecutionRole.Arn
          PolicyName: RunTaskPolicy
  
  ####### Cloudwatch Dashboard to Enable viewing of CloudQuery State#####
  OperationalDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties: 
      DashboardBody: !Sub | 
        {"widgets":[{"height":6,"width":24,"y":12,"x":0,"type":"log","properties":{"query":"SOURCE '${LogGroup}' | fields @timestamp, error,account_id, client_id\n| sort @timestamp desc\n| filter ispresent(level) and ispresent(error) and level = \"error\"\n| limit 20","region":"${AWS::Region}","title":"Errors","view":"table"}},{"height":6,"width":12,"y":0,"x":0,"type":"log","properties":{"query":"SOURCE '${LogGroup}' | \nparse message '* fetched: * Warnings: * Errors: *' as @m, @fetchedCount, @warnings, @errors \n| display message, @fetchedCount, @warnings, @errors \n| filter ispresent(message) and message like /Provider .* fetch summary:/\n| stats sum(@fetchedCount), sum(@warnings), sum(@errors) by bin(5m)\n","region":"${AWS::Region}","title":"Summary Results","view":"timeSeries","stacked":false}},{"height":6,"width":12,"y":6,"x":0,"type":"log","properties":{"query":"SOURCE '${LogGroup}' | fields @timestamp, @message \n| filter ispresent(count)\n| stats sum(count) by bin(1min)\n","region":"${AWS::Region}","title":"Resources Per Minute","view":"timeSeries","stacked":false}},{"type":"log","x":12,"y":0,"width":12,"height":6,"properties":{"query":"SOURCE '${LogGroup}' | fields @timestamp, @message\n| sort @timestamp desc\n| filter ispresent(instance_id) | stats fromMillis(earliest(@timestamp)) as start, fromMillis(latest(@timestamp)) as end, (max(@timestamp) - min(@timestamp))/1000 as `duration (s)` by instance_id","region":"${AWS::Region}","stacked":false,"title":"Invocations","view":"table"}}]}
 
Outputs:
  s3bucket:
    Value: !Ref S3Bucket
  ClusterId:
    Value: !Ref ECSCluster
  TaskArn:
    Value: !Ref ScheduledWorkerTask    
  Subnets:
    Description: A list of the private subnets
    Value: !If [DeployVPC,!Join [ ",", [ !Ref PrivateSubnet1, !Ref PrivateSubnet2 ]], !Ref PrivateSubnetIds]
  SecurityGroups:
    Value: !Join [ ",", [ !Ref ECSSecurityGroup, !Ref PgServerlessSecurityGroup]]
  FetchOrchestrator:
    Value: !Ref FetchOrchestrator